{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Merged_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>Day of Month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Avg Population</th>\n",
       "      <th>Avg Households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>51.455989</td>\n",
       "      <td>-0.043536</td>\n",
       "      <td>23:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>No Crime</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>51.475561</td>\n",
       "      <td>-0.075330</td>\n",
       "      <td>23:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>No Crime</td>\n",
       "      <td>39.466667</td>\n",
       "      <td>15.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>51.533030</td>\n",
       "      <td>-0.203277</td>\n",
       "      <td>23:07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>No Crime</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>51.553184</td>\n",
       "      <td>-0.176043</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>No Crime</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>17.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>51.553184</td>\n",
       "      <td>-0.176043</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>No Crime</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>17.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Latitude  Longitude      Time  Weekday  Hour  Min  \\\n",
       "0  2016-05-31  51.455989  -0.043536  23:01:00        1    23    1   \n",
       "1  2016-05-31  51.475561  -0.075330  23:05:00        1    23    5   \n",
       "2  2016-05-31  51.533030  -0.203277  23:07:00        1    23    7   \n",
       "3  2016-05-31  51.553184  -0.176043  23:10:00        1    23   10   \n",
       "4  2016-05-31  51.553184  -0.176043  23:10:00        1    23   10   \n",
       "\n",
       "   Day of Month  Month    Labels  Avg Population  Avg Households  \n",
       "0            31      5  No Crime       42.333333       14.000000  \n",
       "1            31      5  No Crime       39.466667       15.066667  \n",
       "2            31      5  No Crime      159.000000       74.000000  \n",
       "3            31      5  No Crime       47.000000       17.750000  \n",
       "4            31      5  No Crime       47.000000       17.750000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_crime= df[df['Labels']=='No Crime']\n",
    "drugs= df[df['Labels']!='Drug Possesion']\n",
    "vand = df[df['Labels']!='Vandalism']\n",
    "guns = df[df['Labels']!='Firearms Possesion']\n",
    "skeng = df[df['Labels']!='Knife or Offensive Weapon Possesion']\n",
    "fight = df[df['Labels']!='Violence']\n",
    "sample_nc = no_crime.sample(10000)\n",
    "sample_dg = drugs.sample(10000)\n",
    "sample_vd = vand.sample(10000)\n",
    "sample_sk = guns.sample(10000)\n",
    "sample_ft = fight.sample(10000)\n",
    "len(sample_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Crime', 'Drug Possesion', 'Vandalism', 'Firearms Possesion',\n",
       "       'Knife or Offensive Weapon Possesion', 'Violence'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.concat([sample_nc,sample_dg,sample_vd,sample_sk,sample_ft])\n",
    "df= test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "tra = df[:40000]\n",
    "tes = df[40000:]\n",
    "df=tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
    "X= np.array([df['Latitude'],df['Longitude'],df['Weekday'],df['Hour'],df['Min'],df['Day of Month'],df['Month'],df['Avg Population'],df['Avg Households']])\n",
    "#X= np.array([df['Latitude'],df['Longitude'],df['Weekday'],df['Hour'],df['Min'],df['Day of Month'],df['Month'],df['Avg Population']])\n",
    "X= X.transpose()\n",
    "y = df['Labels']\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=0)\n",
    "Xtest= np.array([tes['Latitude'],tes['Longitude'],tes['Weekday'],tes['Hour'],tes['Min'],tes['Day of Month'],tes['Month'],tes['Avg Population'],tes['Avg Households']])\n",
    "Xtest= Xtest.transpose()\n",
    "clf.fit(X,y)\n",
    "testpred = clf.predict(Xtest)\n",
    "trainpred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dario\\Anaconda3\\envs\\COMP6246\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 100}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimators = [100]\n",
    "depths = [10,15,20]\n",
    "params = [{'n_estimators': estimators, 'max_depth': depths}]\n",
    "\n",
    "forrest = RandomForestClassifier()\n",
    "gridsearch = GridSearchCV(forrest, params, cv=5, scoring='f1_weighted')\n",
    "gridsearch.fit(X,y)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 100}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_\n",
    "#gridsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Crime', 'Drug Possesion', 'Vandalism', 'Firearms Possesion'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(testpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Crime', 'Drug Possesion', 'Vandalism', 'Firearms Possesion',\n",
       "       'Knife or Offensive Weapon Possesion', 'Violence'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(tes['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabs, trainlabs = tes['Labels'], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.81019801, 0.67204301, 0.83870968, 1.        , 0.5       ]),\n",
       " array([0.99133819, 0.09137427, 0.08306709, 0.05      , 0.13333333]),\n",
       " array([0.89166149, 0.16087516, 0.15116279, 0.0952381 , 0.21052632]),\n",
       " array([7966, 1368,  626,   20,   15], dtype=int64))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "#score, score1 = f1_score(b,a,average='micro'), f1_score(b2,a2,average='micro')\n",
    "#score, score1\n",
    "\n",
    "score, score1 = precision_recall_fscore_support(b, a, average=None, labels=pd.unique(a)), precision_recall_fscore_support(b2, a2, average=None, labels=pd.unique(a2))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87519625, 0.99217141, 0.99417637, 1.        , 0.93333333,\n",
       "        1.        ]),\n",
       " array([0.99927666, 0.44232182, 0.45908567, 0.296875  , 0.525     ,\n",
       "        0.16666667]),\n",
       " array([0.93312972, 0.61186634, 0.62812089, 0.45783133, 0.672     ,\n",
       "        0.28571429]),\n",
       " array([31797,  5444,  2603,    64,    80,    12], dtype=int64))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14369762, 0.14244145, 0.06778292, 0.10172382, 0.10503822,\n",
       "       0.11317693, 0.08111728, 0.12487044, 0.12015133])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob= clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.93215199e-02, 1.33157550e-03, 3.55947485e-04, 8.62583790e-01,\n",
       "        6.62111402e-02, 1.96026723e-04],\n",
       "       [8.90053232e-02, 1.02786506e-02, 9.08706666e-05, 8.52678930e-01,\n",
       "        4.79462254e-02, 0.00000000e+00],\n",
       "       [5.65426194e-02, 2.61678711e-03, 5.37151981e-05, 2.68297602e-01,\n",
       "        6.72489276e-01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [7.56778267e-02, 1.97447116e-04, 3.92171134e-04, 8.90455418e-01,\n",
       "        3.32771372e-02, 0.00000000e+00],\n",
       "       [7.47697879e-02, 2.18835452e-03, 5.62129633e-04, 8.85979899e-01,\n",
       "        3.64998293e-02, 0.00000000e+00],\n",
       "       [9.67083763e-02, 6.13245474e-04, 6.75310813e-04, 8.69590205e-01,\n",
       "        3.22827667e-02, 1.30095794e-04]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = ['bo','ro','go','co', 'mo', 'yo']\n",
    "uniq = pd.unique(b)\n",
    "for i in range(len(color_map)):\n",
    "    indx = b==uniq[1]\n",
    "    plt.plot(Xtest[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8074, 0.887725)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, score1 = f1_score(testlabs,testpred,average='micro'), f1_score(trainlabs,trainpred,average='micro')\n",
    "score, score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime_random_forest_model.m']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, \"crime_random_forest_model.m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
